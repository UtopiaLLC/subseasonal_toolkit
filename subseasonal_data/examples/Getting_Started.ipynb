{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with the Subseasonal Data Python Package\n",
    "\n",
    "The `subseasonal_data` package provides an API for loading and manipulating the **SubseasonalClimateUSA** dataset developed for training and benchmarking subseasonal forecasting models.  Here, _subseasonal_ refers to climate and weather forecasts made 2-6 weeks in advance.\n",
    "See [DATA.md](../DATA.md) for a detailed description of dataset contents, sources, and processing.\n",
    "\n",
    "The underlying data is made available through Azure and is updated periodically. To download the data through this package, you will need to have the Azure Storage CLI [`azcopy`](https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy) installed on your machine.\n",
    "\n",
    "**Data directory structure (on Azure):**\n",
    "* `dataframes`: individual dataframes containing meteorological measurements and dynamical model forecasts\n",
    "* `combined_dataframes`: combination dataframes pairing temperature and precipitation target variables with lagged measurement and forecast features\n",
    "* `masks`: lat-lon filters for the contiguous U.S. and Western U.S.\n",
    "\n",
    "**Package structure:**\n",
    "* `downloader`: methods for manually downloading the data\n",
    "* `data_loaders`: methods for loading the data. By default, these can download data on demand.\n",
    "\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "1. [Download all subseasonal forecasting data](#Download-all-subseasonal-forecasting-data)\n",
    "2. [Download one file](#Download-one-file)\n",
    "3. [Download on demand](#Download-on-demand)\n",
    "\n",
    "Requirements: `Python 3.6+`, `azcopy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subseasonal_data import downloader, data_loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all subseasonal forecasting data\n",
    "\n",
    "Use the `subseasonal_data.downloader.download` function to download the entire dataset on disk. **WARNING:** The entire dataset is approximately 175GB in size, proceed with caution. \n",
    "\n",
    "There are two ways to specify where to download the data:\n",
    "* **Default:** user's home directory\n",
    "    * Windows: `C:\\users\\[username]\\subseasonal_data`\n",
    "    * Linux, Mac: `/home/[username]/subseasonal_data`\n",
    "* **Environment Variable:** specify path via the `SUBSEASONALDATA_PATH` environmental variable. **Note:** this will be where the package will look for the data in the future, so make sure this environmental variable is permanent. If this variable is undefined, it will default to the `subseasonal_data` folder in the user's home directory.\n",
    "\n",
    "To find out where the data will be/was downloaded, use the `subseasonal_data.downloader.get_subseasonal_data_path` method. \n",
    "\n",
    "**Note:** The initial download can take a while, however subsequent downloads will just sync the data which is faster most of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test azcopy\n",
    "downloader.check_azcopy_install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pool001/moprescu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get download path (uncomment below)\n",
    "downloader.get_subseasonal_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from the 'dataframes' directory...\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job a291ab41-1a52-c14c-49c3-a3a62b041ef9 has started\n",
      "Log file is located at: /home/moprescu/.azcopy/a291ab41-1a52-c14c-49c3-a3a62b041ef9.log\n",
      "\n",
      "0 Files Scanned at Source, 0 Files Scanned at Destination\n",
      "\n",
      "Job a291ab41-1a52-c14c-49c3-a3a62b041ef9 Summary\n",
      "Files Scanned at Source: 199\n",
      "Files Scanned at Destination: 199\n",
      "Elapsed Time (Minutes): 0.0336\n",
      "Number of Copy Transfers for Files: 0\n",
      "Number of Copy Transfers for Folder Properties: 0 \n",
      "Total Number Of Copy Transfers: 0\n",
      "Number of Copy Transfers Completed: 0\n",
      "Number of Copy Transfers Failed: 0\n",
      "Number of Deletions at Destination: 0\n",
      "Total Number of Bytes Transferred: 0\n",
      "Total Number of Bytes Enumerated: 0\n",
      "Final Job Status: Completed\n",
      "\n",
      "Downloading data from the 'combined_dataframes' directory...\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job 7954003e-0dc2-6442-568d-cc6ef41242dc has started\n",
      "Log file is located at: /home/moprescu/.azcopy/7954003e-0dc2-6442-568d-cc6ef41242dc.log\n",
      "\n",
      "0 Files Scanned at Source, 0 Files Scanned at Destination\n",
      "\n",
      "Job 7954003e-0dc2-6442-568d-cc6ef41242dc Summary\n",
      "Files Scanned at Source: 41\n",
      "Files Scanned at Destination: 41\n",
      "Elapsed Time (Minutes): 0.0335\n",
      "Number of Copy Transfers for Files: 0\n",
      "Number of Copy Transfers for Folder Properties: 0 \n",
      "Total Number Of Copy Transfers: 0\n",
      "Number of Copy Transfers Completed: 0\n",
      "Number of Copy Transfers Failed: 0\n",
      "Number of Deletions at Destination: 0\n",
      "Total Number of Bytes Transferred: 0\n",
      "Total Number of Bytes Enumerated: 0\n",
      "Final Job Status: Completed\n",
      "\n",
      "Downloading data from the 'masks' directory...\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job 85900b47-ef01-db44-74eb-38b94c0daca0 has started\n",
      "Log file is located at: /home/moprescu/.azcopy/85900b47-ef01-db44-74eb-38b94c0daca0.log\n",
      "\n",
      "0 Files Scanned at Source, 3 Files Scanned at Destination\n",
      "\n",
      "Job 85900b47-ef01-db44-74eb-38b94c0daca0 Summary\n",
      "Files Scanned at Source: 3\n",
      "Files Scanned at Destination: 3\n",
      "Elapsed Time (Minutes): 0.0334\n",
      "Number of Copy Transfers for Files: 0\n",
      "Number of Copy Transfers for Folder Properties: 0 \n",
      "Total Number Of Copy Transfers: 0\n",
      "Number of Copy Transfers Completed: 0\n",
      "Number of Copy Transfers Failed: 0\n",
      "Number of Deletions at Destination: 0\n",
      "Total Number of Bytes Transferred: 0\n",
      "Total Number of Bytes Enumerated: 0\n",
      "Final Job Status: Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download/ sync data\n",
    "downloader.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download one file\n",
    "\n",
    "To download one file only, use the `subseasonal_data.downloader.download_file` method. You will need to specify the data directory on Azure (see [Getting Started with the Subseasonal Data Python Package](#Getting-Started-with-the-Subseasonal-Data-Python-Package) ), as well as the file name. \n",
    "\n",
    "You can list the files in a data directory using `subseasonal_data.downloader.list_subdir_files`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: all_data-contest_precip_34w.feather;  Content Length: 5.28 GiB\n",
      "INFO: all_data-contest_precip_56w.feather;  Content Length: 5.28 GiB\n",
      "INFO: all_data-contest_tmp2m_34w.feather;  Content Length: 2.76 GiB\n",
      "INFO: all_data-contest_tmp2m_56w.feather;  Content Length: 2.76 GiB\n",
      "INFO: all_data-salient_fri.feather;  Content Length: 66.49 MiB\n",
      "INFO: all_data-us_precip_34w.feather;  Content Length: 8.88 GiB\n",
      "INFO: all_data-us_precip_56w.feather;  Content Length: 8.88 GiB\n",
      "INFO: all_data-us_tmp2m_34w.feather;  Content Length: 4.63 GiB\n",
      "INFO: all_data-us_tmp2m_56w.feather;  Content Length: 4.63 GiB\n",
      "INFO: all_data_no_NA-contest_precip_34w.feather;  Content Length: 2.05 MiB\n",
      "INFO: all_data_no_NA-contest_precip_56w.feather;  Content Length: 2.04 MiB\n",
      "INFO: all_data_no_NA-contest_tmp2m_34w.feather;  Content Length: 2.01 MiB\n",
      "INFO: all_data_no_NA-contest_tmp2m_56w.feather;  Content Length: 2.00 MiB\n",
      "INFO: all_data_no_NA-us_precip_34w.feather;  Content Length: 3.38 MiB\n",
      "INFO: all_data_no_NA-us_precip_56w.feather;  Content Length: 3.36 MiB\n",
      "INFO: all_data_no_NA-us_tmp2m_34w.feather;  Content Length: 3.29 MiB\n",
      "INFO: all_data_no_NA-us_tmp2m_56w.feather;  Content Length: 3.27 MiB\n",
      "INFO: date_data-contest_precip_34w.feather;  Content Length: 5.63 MiB\n",
      "INFO: date_data-contest_precip_56w.feather;  Content Length: 5.63 MiB\n",
      "INFO: date_data-contest_tmp2m_34w.feather;  Content Length: 3.79 MiB\n",
      "INFO: date_data-contest_tmp2m_56w.feather;  Content Length: 3.79 MiB\n",
      "INFO: date_data-us_precip_34w.feather;  Content Length: 5.63 MiB\n",
      "INFO: date_data-us_precip_56w.feather;  Content Length: 5.63 MiB\n",
      "INFO: date_data-us_tmp2m_34w.feather;  Content Length: 3.79 MiB\n",
      "INFO: date_data-us_tmp2m_56w.feather;  Content Length: 3.79 MiB\n",
      "INFO: lat_lon_data-contest_precip_34w.feather;  Content Length: 17.09 KiB\n",
      "INFO: lat_lon_data-contest_precip_56w.feather;  Content Length: 17.09 KiB\n",
      "INFO: lat_lon_data-contest_tmp2m_34w.feather;  Content Length: 17.09 KiB\n",
      "INFO: lat_lon_data-contest_tmp2m_56w.feather;  Content Length: 17.09 KiB\n",
      "INFO: lat_lon_data-us_precip_34w.feather;  Content Length: 21.47 KiB\n",
      "INFO: lat_lon_data-us_precip_56w.feather;  Content Length: 21.47 KiB\n",
      "INFO: lat_lon_data-us_tmp2m_34w.feather;  Content Length: 21.47 KiB\n",
      "INFO: lat_lon_data-us_tmp2m_56w.feather;  Content Length: 21.47 KiB\n",
      "INFO: lat_lon_date_data-contest_precip_34w.feather;  Content Length: 2.52 GiB\n",
      "INFO: lat_lon_date_data-contest_precip_56w.feather;  Content Length: 2.52 GiB\n",
      "INFO: lat_lon_date_data-contest_tmp2m_34w.feather;  Content Length: 2.12 GiB\n",
      "INFO: lat_lon_date_data-contest_tmp2m_56w.feather;  Content Length: 2.12 GiB\n",
      "INFO: lat_lon_date_data-us_precip_34w.feather;  Content Length: 4.25 GiB\n",
      "INFO: lat_lon_date_data-us_precip_56w.feather;  Content Length: 4.25 GiB\n",
      "INFO: lat_lon_date_data-us_tmp2m_34w.feather;  Content Length: 3.56 GiB\n",
      "INFO: lat_lon_date_data-us_tmp2m_56w.feather;  Content Length: 3.57 GiB\n"
     ]
    }
   ],
   "source": [
    "# List files in 'combined_dataframes'\n",
    "downloader.list_subdir_files(data_subdir=\"combined_dataframes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job 4a18a083-ec54-e74c-7cd3-0233c470073e has started\n",
      "Log file is located at: /home/moprescu/.azcopy/4a18a083-ec54-e74c-7cd3-0233c470073e.log\n",
      "\n",
      "0 Files Scanned at Source, 1 Files Scanned at Destination\n",
      "\n",
      "Job 4a18a083-ec54-e74c-7cd3-0233c470073e Summary\n",
      "Files Scanned at Source: 1\n",
      "Files Scanned at Destination: 1\n",
      "Elapsed Time (Minutes): 0.0334\n",
      "Number of Copy Transfers for Files: 0\n",
      "Number of Copy Transfers for Folder Properties: 0 \n",
      "Total Number Of Copy Transfers: 0\n",
      "Number of Copy Transfers Completed: 0\n",
      "Number of Copy Transfers Failed: 0\n",
      "Number of Deletions at Destination: 0\n",
      "Total Number of Bytes Transferred: 0\n",
      "Total Number of Bytes Enumerated: 0\n",
      "Final Job Status: Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download/ sync a file\n",
    "downloader.download_file(data_subdir=\"combined_dataframes\", filename=\"all_data-us_precip_34w.feather\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download on demand\n",
    "\n",
    "As a space-efficient alternative, the data loader methods can download data on demand if the `sync` flag is set to true. `sync=True` is the default for these methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syncing data....Set sync=False to avoid this step.\n",
      "INFO: Any empty folders will not be processed, because source and/or destination doesn't have full folder support\n",
      "\n",
      "Job 2ca29862-ed03-b640-6b21-0c4bf39b0135 has started\n",
      "Log file is located at: /home/moprescu/.azcopy/2ca29862-ed03-b640-6b21-0c4bf39b0135.log\n",
      "\n",
      "0 Files Scanned at Source, 1 Files Scanned at Destination\n",
      "\n",
      "Job 2ca29862-ed03-b640-6b21-0c4bf39b0135 Summary\n",
      "Files Scanned at Source: 1\n",
      "Files Scanned at Destination: 1\n",
      "Elapsed Time (Minutes): 0.0336\n",
      "Number of Copy Transfers for Files: 0\n",
      "Number of Copy Transfers for Folder Properties: 0 \n",
      "Total Number Of Copy Transfers: 0\n",
      "Number of Copy Transfers Completed: 0\n",
      "Number of Copy Transfers Failed: 0\n",
      "Number of Deletions at Destination: 0\n",
      "Total Number of Bytes Transferred: 0\n",
      "Total Number of Bytes Enumerated: 0\n",
      "Final Job Status: Completed\n",
      "\n",
      "Loading /pool001/moprescu/dataframes/gt-us_tmp2m-14d.h5\n"
     ]
    }
   ],
   "source": [
    "df = data_loaders.get_ground_truth(\"us_tmp2m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>start_date</th>\n",
       "      <th>tmp2m</th>\n",
       "      <th>tmp2m_sqd</th>\n",
       "      <th>tmp2m_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1979-01-01</td>\n",
       "      <td>18.932249</td>\n",
       "      <td>373.676582</td>\n",
       "      <td>3.904680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1979-01-02</td>\n",
       "      <td>18.531180</td>\n",
       "      <td>357.715187</td>\n",
       "      <td>3.782928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1979-01-03</td>\n",
       "      <td>18.178591</td>\n",
       "      <td>343.465285</td>\n",
       "      <td>3.606123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1979-01-04</td>\n",
       "      <td>18.764877</td>\n",
       "      <td>361.311215</td>\n",
       "      <td>3.031604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1979-01-05</td>\n",
       "      <td>19.305099</td>\n",
       "      <td>377.889830</td>\n",
       "      <td>2.281007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lat    lon start_date      tmp2m   tmp2m_sqd  tmp2m_std\n",
       "0  26.0  279.0 1979-01-01  18.932249  373.676582   3.904680\n",
       "1  26.0  279.0 1979-01-02  18.531180  357.715187   3.782928\n",
       "2  26.0  279.0 1979-01-03  18.178591  343.465285   3.606123\n",
       "3  26.0  279.0 1979-01-04  18.764877  361.311215   3.031604\n",
       "4  26.0  279.0 1979-01-05  19.305099  377.889830   2.281007"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
